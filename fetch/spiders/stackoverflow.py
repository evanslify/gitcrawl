# -*- coding: utf-8 -*-
import scrapy
from fetch.items import StackOverflowItem
import json


class StackOverflowSpider(scrapy.Spider):
    name = "stackexchangesites"

    def __init__(self, *args, **kwargs):
        super(StackOverflowSpider, self).__init__(*args, **kwargs)
        self.target = kwargs.get('target')
        self.sorting = kwargs.get('sorting', 'activity')
        self.query_size = int(kwargs.get('size', 30))
        self.site = kwargs.get('site')
        self.visited_url = []

    def callnext(self, response=None, caller=None, start_meta=None):
        try:
            meta = response.request.meta
        except AttributeError:
            meta = start_meta

        callstack = meta['callstack']

        if len(callstack) > 0:
            target = callstack.pop(0)
            url = target['url']

            if url in self.visited_url:
                # url is visited, drawing the next call from callstack
                target = callstack.pop(0)
                url = target['url']
            else:
                self.visited_url.append(url)

            yield scrapy.Request(
                url=url, meta=meta,
                callback=target['callback'], errback=self.callnext)

        else:
            items = StackOverflowItem()
            loader = response.meta.get('Loader')
            items['UserInfo'] = loader['UserInfo']
            items['PostInfo'] = loader['PostInfo']
            items['identifier'] = loader['identifier']
            yield items


# ----------------------------------------------------------------
# Start declaring methods to parse JSON items.
# ----------------------------------------------------------------

    def parse_comment(self, input):
        '''
        Parses a list of comment objects,
        and returns a list of parsed comments
        '''
        if input is None:
            comment_list = None
        else:
            comment_list = []
            for comment in input:
                comment_list.append(comment)
        return comment_list

    def parse_answer(self, input):
        '''
        Parses a list of answer objects,
        and returns a list of answer comments
        '''
        if input is None:
            answer_list = None
        else:
            answer_list = []
            for answer in input:
                answer_list.append(answer)
        return answer_list

    def parse_question(self, input):
        '''
        Parse a list of question objects,
        returns a list of parsed questions.
        '''
        if input is None:
            question_list = None
        else:
            question_list = []
            for question in input:
                question_list.append(question)
        return question_list

# ----------------------------------------------------------------
# End declaring methods to parse JSON items.
# ----------------------------------------------------------------

    def start_requests(self):
        # override scrapy's own method to start requests.
        meta = scrapy.Request.meta
        # declaring item loader's layout.
        meta = {
            'callstack': [],
            'Loader': {
                'UserInfo': {},
                'PostInfo': {
                    'QuestionInfo': [],
                    'AnswerInfo': []
                },
                'identifier': '',
            }
        }

        callstack = meta['callstack']

        # generate the query URI to search for username
        url = self.parse_arguments()
        callstack.extend([
            {'url': url, 'callback': self.search_user}])

        return self.callnext(start_meta=meta)

    def parse_arguments(self):
        # returns a list, generated by parsing start arguments

        if not self.target and not self.site:
            argerror = 'Missing Argument'
            raise Exception(argerror)

        allow_sortings = ['activity', 'creation', 'votes']
        if self.sorting not in allow_sortings:
            raise Exception('Invalid sorting method given.')

        self.key_dict = {
            'key': '&key=Hqgd6TsMOJsOSdR3UNkVmg((',
            'search_u_filter': '&filter=!bZPqQ_eGrS84JR',
            'question_filter': (
                '&filter=)jxf1*W)HMRItxIKZut.fsS_MratGaN(M0.UccqWSSk2wP_V'),
            'answer_filter': '&filter=!--pn9sThVUTv',
            'target': self.target,
            'site': self.site,
            'size': self.query_size,
            'sort': self.sorting
        }

        url = (
            'https://api.stackexchange.com/2.2/users/{target}?'
            'pagesize=1&order=asc&min=1&sort=name&site='
            '{site}{search_u_filter}{key}').format(**self.key_dict)
        return url

    def search_user(self, response):
        '''
            StackExchange sites does not support searching for users
            by email or other identifiers.
            The only way to make sure the user is that we're looking for,
            is by kindly asking user to send us OAuth tokens and
            use that token to make API queries.
            This not viable for now(August 7 2015) so unfortunately
            we go to API search page and humbly takes the first result
            that API returned as the user that we're looking for.
            August 21th 2015: This spider will query by user_id from now on.
        '''
        '''
            Parses user search page for user infomation.
        '''
        jr = json.loads(response.body_as_unicode())
        callstack = response.meta['callstack']
        loader = response.meta['Loader']
        item = jr['items'][0]
        loader['UserInfo'] = item
        self.key_dict['account_id'] = item['account_id']
        self.key_dict['user_id'] = item['user_id']
        user_answer_count = item['answer_count']
        user_question_count = item['question_count']
        # use stackoverflow ID as our unique identifier.
        loader['identifier'] = (
            str('{user_id}') + ';{site}').format(**self.key_dict)

        # generate the next url:
        # to parse the list of top voted ~100 posts by this user
        if user_question_count:
            asked_by_user_url = (
                'https://api.stackexchange.com/2.2/users/{user_id}/questions?'
                'pagesize={size}&order=desc&sort={sort}&site={site}'
                '{question_filter}{key}').format(**self.key_dict)
            callstack.append(
                {'url': asked_by_user_url, 'callback': self.parse_user_asked})

        if user_answer_count:
            answer_list_url = (
                'https://api.stackexchange.com/2.2/users/{user_id}/answers?'
                'pagesize={size}&order=desc&sort={sort}&site={site}'
                '{answer_filter}{key}').format(**self.key_dict)
            callstack.append({
                'url': answer_list_url,
                'callback': self.parse_user_answer_list})

        return self.callnext(response)

    def parse_user_asked(self, response):
        jr = json.loads(response.body_as_unicode())
        loader = response.meta['Loader']
        items = loader['PostInfo']['QuestionInfo']

        questions = jr.get('items')
        items.append(questions)

        return self.callnext(response)

    def parse_user_answer_list(self, response):

        jr = json.loads(response.body_as_unicode())
        callstack = response.meta['callstack']

        ids = jr.get('items')
        id_list = []
        for one_question in ids:
            id_ = one_question.get('question_id')
            id_list.append(id_)
        id_list_str = ';'.join(str(x) for x in id_list)

        url = (
            'http://api.stackexchange.com/2.2/questions/{id_list}?pagesize={si'
            'ze}&order=desc&sort={sort}&site={site}{question_filter}{key}'
        ).format(id_list=id_list_str, **self.key_dict)

        callstack.append({
            'url': url,
            'callback': self.parse_user_answered_questions})

        return self.callnext(response)

    def parse_user_answered_questions(self, response):
        jr = json.loads(response.body_as_unicode())
        loader = response.meta['Loader']
        items = loader['PostInfo']['AnswerInfo']

        questions = jr.get('items')
        items.append(questions)

        return self.callnext(response)
